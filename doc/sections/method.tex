\documentclass[report.tex]{subfile}

\begin{document}

\section{Method}
A classifier has been created by training a multilayer perceptron neural
network with the given training data of hand written digits. The given data is
first partitioned into three subsets. The training data is preprocessed and
turned into rasterized images of the digits. The images are then used to train
the neural network.

\subsection{Partitioning of training data}
The training data is split up into three different subsets. Two sets are used
for the training process; the training set and the validation set. The training
set is used to train multiple classifiers with different parameters, and the
validation set is used to select which of these classifiers to use. The third
and final set, the test set, is used after the training is completed in order
to evaluate how well the classifier performs. The subsets were selected
randomly but uniformly for each digit. The distribution was 70\%, 10\% and 20\%
for the training, validation and test set respectively.

\subsection{Preprocessing}
The input data for each data is given as a list of 3D-coordinates that together
form a curve in the shape of a digit. As the digits are aligned along the plane
of the XY axes, the Z-coordinate is simply ignored and the curves are treated
as 2D only. The digits are first translated and scaled to a common location and
size and then rasterized into a grayscale image. The grayscale image is then
dilated so that the digits become thicker. The intensity of each pixel is
finally treated as a large vector. Each pixel represents an input neuron in the
neural network.

\subsubsection{Scaling}
\begin{figure}
    \centering
    \begin{subfigure}[c]{0.3\textwidth}
        \resizebox{\textwidth}{!}{\input{build/fig/scale_3d1.tex}}
        \caption{Six \#1, raw}
    \end{subfigure}%
    {\large $\rightarrow$}
    \begin{subfigure}[c]{0.3\textwidth}
        \resizebox{\textwidth}{!}{\input{build/fig/scale_before1.tex}}
        \caption{Six \#1, projected}
    \end{subfigure}%
    {\large $\rightarrow$}
    \begin{subfigure}[c]{0.3\textwidth}
        \resizebox{\textwidth}{!}{\input{build/fig/scale_after1.tex}}
        \caption{Six \#1, scaled}
    \end{subfigure}\\
    \begin{subfigure}[c]{0.3\textwidth}
        \resizebox{\textwidth}{!}{\input{build/fig/scale_3d2.tex}}
        \caption{Six \#1, projected}
    \end{subfigure}%
    {\large $\rightarrow$}
    \begin{subfigure}[c]{0.3\textwidth}
        \resizebox{\textwidth}{!}{\input{build/fig/scale_before2.tex}}
        \caption{Six \#2, raw}
    \end{subfigure}%
    {\large $\rightarrow$}
    \begin{subfigure}[c]{0.3\textwidth}
        \resizebox{\textwidth}{!}{\input{build/fig/scale_after2.tex}}
        \caption{Six \#2, scaled}
    \end{subfigure}
    \caption{Two sixes before and after projection and scaling.}
    \label{fig:scaling}
\end{figure}
Because the digits are written at different locations and in different sizes,
scaling and translation is performed to make similar shaped images comparable.
Only the shape of the digit is useful, the location and scale can be changed
without losing any useful information. Figure \ref{fig:scaling} shows two sixes
being scaled.

\subsubsection{Rasterization}
\begin{figure}
    \centering
    \begin{subfigure}[c]{0.3\textwidth}
        \vspace*{-3.5mm}
        \resizebox{\textwidth}{!}{\input{build/fig/rasterize_0.tex}}
        \vspace*{-10mm}
        \caption{Scaled}
    \end{subfigure}%
    {\large $\rightarrow$}
    \begin{subfigure}[c]{0.3\textwidth}
        \centering
        \resizebox{0.8\textwidth}{!}{%
            \includegraphics{build/fig/rasterize_1.png}%
        }
        \vfill
        \caption{Rasterized}
    \end{subfigure}%
    {\large $\rightarrow$}
    \begin{subfigure}[c]{0.3\textwidth}
        \centering
        \resizebox{0.8\textwidth}{!}{%
            \includegraphics{build/fig/rasterize_2.png}%
        }
        \vfill
        \caption{Dilated}
    \end{subfigure}%
    \caption{Rasterization of a two with some noise.}
    \label{fig:raster_noise}
\end{figure}
When the digits are located in the same position and are of similar scale the
digits can be rasterized. The rasterization is performed by rasterizing each
line of the curve. The rasterization is performed by using Xiaolin Wu's line
drawing algorithm. The algorithm is described in Wu's article in \emph{Computer
Graphics}\cite{wu-line}. The rasterization is done such that the image is $W
\times W$ pixels large with $W = 20$.

Each rasterized curve is then added to the final image by taking the maximum
intensity of the previous pixel and the pixel of the curve.

Finally, dilation is performed to make the digits thicker. The dilation is
performed by applying a two-dimensional convolution to the image with the
matrix
\begin{equation*}
    D =
    \begin{bmatrix}
        0.5 & 0.8 & 0.5 \\
        0.8 &   1 & 0.8 \\
        0.5 & 0.8 & 0.5
    \end{bmatrix}.
\end{equation*}
In this way, the inner pixels of digits will be 1 and the edges will be between
0 and 1, which could be useful for the classifier because the same digit
usually have edges in around the same location.

One good thing about rasterization is that it decreases the impact of noise as
is demonstrated in figure \ref{fig:raster_noise}. Also, duplicate overlapping
lines will look the same as if there was only one line.

\subsection{Neural network - multilayer perceptron}
The classifier was implemented using a multi-layer perceptron with one hidden
layer. The input layer consists of all the intensities of the pixels of the
grayscale image resulting from the preprocessing of the input. An additional
fully white pixel is added in order to provide a bias for the weights.

The details of a multi-layer perceptron is described in chapter 6 of the book
\emph{Pattern Classification}\cite{hart-pattern}. Here will only be described
shortly how the classifier of this project was implemented.

\subsubsection{Architecture}
\begin{figure}[h]
    \centering
    \input{doc/fig/mlp.tex}
    \caption{Visual representation of the neural network.}
    \label{fig:mlp}
\end{figure}
The network consist of three layers of neurons as shown in \ref{fig:mlp}.  The
first layer is the input layer $x$ with $\beta+1=W^2+1$ neurons, where $W$ is
the width and height of the image of each digit. The input layer consists of
each of the pixels plus an additional constant 1 which provides a bias.

The second layer is the hidden layer with $H$ neurons.

The last layer is the output layer, one neuron for each class of digit. The
layer therefore has $D=10$ neurons. Between each consecutive layer are weights
between each combination of neurons from each layer. These are represented by
matrices. The matrix $w^h$ contains all the weights between the output layer
and the hidden layer. $w^h_{i,k}$ is the weight from the $x_k$ input neuron to
the $y^h_i$ neuron. Similarly, the matrix $w^o$ contains weights such that
$w^o_{j,i}$ is the weight from the hidden $y^h_i$ neuron to the $y^o_j$ output
neuron.

%&x \in M_{\beta \times 1}, \qquad
%\overline x = \left( x, 1 \right) \in M_{(\beta+1) \times 1}, \\
%&y^h \in M_{H \times 1}, \qquad
%\overline y^h = \left( y^h, 1 \right) \in M_{(H+1) \times 1}, \\
%&y^o \in M_{D \times 1}, \\
%&w^h \in M_{H \times (\beta + 1)}, \qquad
%\overline w^h \in M_{H \times \beta}, \\
%&w^o \in M_{D \times (H + 1)}, \qquad
%\overline w^o \in M_{D \times H} \\
%&i = 1..H, \\
%&j = 1..D, \\
\subsubsection{Feedforward}
The feedforward operation takes an input layer and a network in the form of
weigths and gives values for all the neurons in the hidden layer and the output
layer. Each neuron of each hidden layer is given by summing all the weighted
values of the previous layer and then applying an activation function. In this
implementation, the $\tanh$ function is used and the $i$:th neuron of the
single hidden layer is calculated as
\begin{equation*}
    y^h_i = \tanh \left(
                    \sum_{k=1}^{\beta} x_k w^h_{i,k} + w^h_{i,\beta+1}
                   \right)
           = \tanh \left( w^h_i \cdot \overline x \right).
\end{equation*}
The output layer is calculated similarly but without the activation function as
\begin{equation*}
    y^o_j = \sum_{i=1}^{H} y^h_i w^o_{j,i} + w^o_{j,H+1}
          = w^o_j \cdot \overline y^h.
\end{equation*}

\subsubsection{Backpropagation}
When the feedforward operation has been performed, we can compare the given
result $y^o$ in the output layer with the wanted result $y^w$. For the wanted
result $y^w$, the neuron which represents the given digit is 1 and all
remaining neurons are zero.

It is then possible to adjust the weights in order to make the network get a
result closer to the wanted result when performing the feedforward operation.
This can be done with something called backpropagation. In short, it works by
using gradient descent to find a local minimum in the error function. The new
weights are calculated by subtracting the previous weights with the gradient as
\begin{align*}
    &J = \frac{(y^o - y^w)^2}{2}, \\
    &w^o_{j,i}(\textrm{new}) = w^o_{j,i} - \rho \; \frac{\partial J}{\partial w^o_{j,i}}
               = w^o_{j,i} - \rho \; \overline y^h_i (y^o_j - y^w_j)\\
    &w^h_{i,k}(\textrm{new}) = w^h_{i,k} - \rho \; \frac{\partial J}{\partial w^h_{i,k}}
               = w^h_{i,k} - \rho \; w^o_i(y^o - y^w)
                             \frac{\partial y^h_i}{\partial w^h_{i,k}}\\
\end{align*}
where $\rho$ is a constant called the learning rate which determines how fast
the descent will be. The partial derivative $\frac{\partial y^h_i}{\partial
w^h_{i,k}}$ is the partial derivative of the activation function which can be
further simplified and approximated as
\begin{align*}
    \frac{\partial y^h_i}{\partial w^h_{i,k}}
        &= \textrm{sech}^2\left( w^h_i \cdot \overline x \right) x_k \\
        &= \left(1-\left( w^h_i \cdot \overline x \right)^2
            + \mathcal{O}\left( w^h_i \cdot \overline x \right)^4
           \right) x_k\\
        &= \left(1-\left(\tanh\left( w^h_i \cdot \overline x\right)
            - \mathcal{O}\left(w^h_i \cdot \overline x \right)^3 \right)^2
                + \mathcal{O}\left( w^h_i \cdot \overline x \right)^4
           \right) x_k\\
        &= \left(1-\left(
                    y^h_i - \mathcal{O}\left(w^h_i \cdot \overline x \right)^3
                   \right)^2
                + \mathcal{O}\left( w^h_i \cdot \overline x \right)^4
           \right) x_k\\
        &\approx \left(1-(y^h_i)^2)\right) x_k.
\end{align*}

\subsubsection{Training}
A classifier, i.e. the weights for the network, are created by applying the
feedforward and backpropagation operation on all of the preprocessed digits.
This is done in multiple iterations each time using the previous weights for
the current iteration. The initial weights are selected randomly. The
implementation performs up to 1000 iterations before abrupting.

This whole process is done multiple times but with different parameters. In the
implementation, the parameter that is altered between the iterations is the
number of neurons in the hidden layer. This implemation uses 16 different
numbers of hidden neurons, ranging from 10 to 25. 

When multiple classifiers has been created, the one that performs the best on
the validation set is selected and used. The performance is measured by the
percentage of correctly classified digits, i.e. the average of the f1 score for
all the classes.

\subsubsection{Classification}
In order to classify a digit the the digit is preprocessed as described above
and the resulting pixels are used as the input for the neural network with the
weights provided by the training. The feedforward operation is performed and
the strongest output neuron determines the classification of the digit.

\end{document}
